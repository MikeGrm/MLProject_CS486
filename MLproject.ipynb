{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c3bd5ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-06T16:38:03.547118Z",
     "iopub.status.busy": "2022-12-06T16:38:03.546367Z",
     "iopub.status.idle": "2022-12-06T16:38:05.676653Z",
     "shell.execute_reply": "2022-12-06T16:38:05.675504Z"
    },
    "papermill": {
     "duration": 2.141543,
     "end_time": "2022-12-06T16:38:05.679988",
     "exception": false,
     "start_time": "2022-12-06T16:38:03.538445",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR IMPORTS HERE\n",
    "import matplotlib.pyplot as plt # for plotting\n",
    "import numpy as np # for transformation\n",
    "\n",
    "import torch # PyTorch package\n",
    "import torchvision # load datasets\n",
    "import torchvision.transforms as transforms # transform data\n",
    "import torch.nn as nn # basic building block for neural neteorks\n",
    "import torch.nn.functional as F # import convolution functions like Relu\n",
    "import torch.optim as optim # optimzer\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81928117",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-06T16:38:05.688984Z",
     "iopub.status.busy": "2022-12-06T16:38:05.688338Z",
     "iopub.status.idle": "2022-12-06T16:38:06.596683Z",
     "shell.execute_reply": "2022-12-06T16:38:06.595119Z"
    },
    "papermill": {
     "duration": 0.916372,
     "end_time": "2022-12-06T16:38:06.599855",
     "exception": false,
     "start_time": "2022-12-06T16:38:05.683483",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = np.load('/kaggle/input/mlprojectdata/train_images.npy')\n",
    "train_labels = np.load('/kaggle/input/mlprojectdata/train_labels.npy')\n",
    "val_data = np.load('/kaggle/input/mlprojectdata/val_images.npy')\n",
    "val_labels = np.load('/kaggle/input/mlprojectdata/val_labels.npy')\n",
    "test_data = np.load('/kaggle/input/mlprojectdata/test_images.npy')\n",
    "test_labels = np.load('/kaggle/input/mlprojectdata/test_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "907036c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-06T16:38:06.608335Z",
     "iopub.status.busy": "2022-12-06T16:38:06.607845Z",
     "iopub.status.idle": "2022-12-06T16:38:06.840430Z",
     "shell.execute_reply": "2022-12-06T16:38:06.839114Z"
    },
    "papermill": {
     "duration": 0.240337,
     "end_time": "2022-12-06T16:38:06.843544",
     "exception": false,
     "start_time": "2022-12-06T16:38:06.603207",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# custom dataset object for dataloaders\n",
    "\n",
    "class My_Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], int(self.y_data[index][0])\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "\n",
    "train_data_for_loader = My_Dataset(torch.FloatTensor(train_data), train_labels)\n",
    "val_data_for_loader = My_Dataset(torch.FloatTensor(val_data), val_labels)\n",
    "test_data_for_loader = My_Dataset(torch.FloatTensor(test_data), test_labels)\n",
    "\n",
    "train_loader = DataLoader(train_data_for_loader, batch_size = 100, shuffle = True)\n",
    "val_loader = DataLoader(val_data_for_loader, batch_size = len(val_data_for_loader), shuffle = False)\n",
    "test_loader = DataLoader(test_data_for_loader, batch_size = len(test_data_for_loader), shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d464e984",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-06T16:38:06.852669Z",
     "iopub.status.busy": "2022-12-06T16:38:06.851543Z",
     "iopub.status.idle": "2022-12-06T16:38:06.864988Z",
     "shell.execute_reply": "2022-12-06T16:38:06.863782Z"
    },
    "papermill": {
     "duration": 0.02098,
     "end_time": "2022-12-06T16:38:06.867723",
     "exception": false,
     "start_time": "2022-12-06T16:38:06.846743",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define and instantiate model\n",
    "\n",
    "class Model(nn.Module):\n",
    "    # YOUR CODE HERE\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "#         self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "#         self.pool = nn.MaxPool2d(2, 2)\n",
    "#         self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(28*28, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 64)\n",
    "        self.fc4 = nn.Linear(64 ,4)\n",
    "\n",
    "    def forward(self, x):\n",
    "#         x = self.pool(F.relu(self.conv1(x)))\n",
    "#         x = self.pool(F.relu(self.conv2(x)))\n",
    "#         x = torch.flatten(x, 1)# flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08781379",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-06T16:38:06.875751Z",
     "iopub.status.busy": "2022-12-06T16:38:06.875153Z",
     "iopub.status.idle": "2022-12-06T16:38:06.880010Z",
     "shell.execute_reply": "2022-12-06T16:38:06.878962Z"
    },
    "papermill": {
     "duration": 0.011476,
     "end_time": "2022-12-06T16:38:06.882453",
     "exception": false,
     "start_time": "2022-12-06T16:38:06.870977",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define and instantiate loss function & optimizer\n",
    "\n",
    "# YOUR CODE HERE\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b2bbd26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-06T16:38:06.890040Z",
     "iopub.status.busy": "2022-12-06T16:38:06.889681Z",
     "iopub.status.idle": "2022-12-06T16:38:33.812167Z",
     "shell.execute_reply": "2022-12-06T16:38:33.810291Z"
    },
    "papermill": {
     "duration": 26.93009,
     "end_time": "2022-12-06T16:38:33.815473",
     "exception": false,
     "start_time": "2022-12-06T16:38:06.885383",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.977476 \tValidation Loss: 0.866815\n",
      "Epoch: 2 \tTraining Loss: 0.833402 \tValidation Loss: 0.774247\n",
      "Epoch: 3 \tTraining Loss: 0.764661 \tValidation Loss: 0.734064\n",
      "Epoch: 4 \tTraining Loss: 0.730930 \tValidation Loss: 0.716077\n",
      "Epoch: 5 \tTraining Loss: 0.705355 \tValidation Loss: 0.664735\n",
      "Epoch: 6 \tTraining Loss: 0.686452 \tValidation Loss: 0.657654\n",
      "Epoch: 7 \tTraining Loss: 0.673567 \tValidation Loss: 0.682813\n",
      "Epoch: 8 \tTraining Loss: 0.663450 \tValidation Loss: 0.660161\n",
      "Epoch: 9 \tTraining Loss: 0.654658 \tValidation Loss: 0.669478\n",
      "Epoch: 10 \tTraining Loss: 0.649528 \tValidation Loss: 0.674620\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# keeping-track-of-losses \n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "for epoch in range(1, 11):\n",
    "    # keep-track-of-training-and-validation-loss\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    \n",
    "    \n",
    "    for data, target in train_loader:\n",
    "        # move-tensors-to-GPU \n",
    "        \n",
    "        # clear-the-gradients-of-all-optimized-variables\n",
    "        optimizer.zero_grad()\n",
    "        # forward-pass: compute-predicted-outputs-by-passing-inputs-to-the-model\n",
    "        output = model(data.view(-1,784))\n",
    "        # calculate-the-batch-loss\n",
    "        loss = criterion(output, target)\n",
    "        # backward-pass: compute-gradient-of-the-loss-wrt-model-parameters\n",
    "        loss.backward()\n",
    "        # perform-a-ingle-optimization-step (parameter-update)\n",
    "        optimizer.step()\n",
    "        # update-training-loss\n",
    "        train_loss += loss.item() * data.size(0)\n",
    "        \n",
    "    # validate-the-model\n",
    "    model.eval()\n",
    "    for data, target in val_loader:\n",
    "        \n",
    "        \n",
    "        output = model(data.view(-1,784))\n",
    "        \n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        # update-average-validation-loss \n",
    "        valid_loss += loss.item() * data.size(0)\n",
    "    \n",
    "    # calculate-average-losses\n",
    "    train_loss = train_loss/len(train_loader.sampler)\n",
    "    valid_loss = valid_loss/len(val_loader.sampler)\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "        \n",
    "    # print-training/validation-statistics \n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "        epoch, train_loss, valid_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85ac5eb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-06T16:38:33.827380Z",
     "iopub.status.busy": "2022-12-06T16:38:33.826881Z",
     "iopub.status.idle": "2022-12-06T16:38:33.844014Z",
     "shell.execute_reply": "2022-12-06T16:38:33.842279Z"
    },
    "papermill": {
     "duration": 0.026494,
     "end_time": "2022-12-06T16:38:33.847115",
     "exception": false,
     "start_time": "2022-12-06T16:38:33.820621",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy: 0.506\n"
     ]
    }
   ],
   "source": [
    "# check accuracy on entire test set\n",
    "\n",
    "# count correct predictions\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    for X_test, y_test in test_loader:\n",
    "        y_pred = model(X_test.view(len(X_test), -1))\n",
    "        predicted = torch.max(y_pred, 1)[1]\n",
    "        correct += (predicted == y_test).sum()\n",
    "\n",
    "# calculate accuracy, print\n",
    "print(f' Accuracy: {correct.item() / len(test_data_for_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26112826",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-06T16:38:33.858010Z",
     "iopub.status.busy": "2022-12-06T16:38:33.857542Z",
     "iopub.status.idle": "2022-12-06T16:38:33.877346Z",
     "shell.execute_reply": "2022-12-06T16:38:33.875650Z"
    },
    "papermill": {
     "duration": 0.028773,
     "end_time": "2022-12-06T16:38:33.880507",
     "exception": false,
     "start_time": "2022-12-06T16:38:33.851734",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# FUNCTION TO SAVE PREDICTIONS TO CSV\n",
    "# call with trained model and DataLoader for test data\n",
    "# will save predictions to .csv in current directory\n",
    "def save_predictions(M, T):\n",
    "    with open('submission.csv', 'w') as out_file:\n",
    "        s = 'Id,Category\\n'\n",
    "        with torch.no_grad():\n",
    "            for X_test, y_test in T:\n",
    "                y_pred = model(X_test.view(len(X_test), -1))\n",
    "                predicted = torch.max(y_pred, 1)[1]\n",
    "                for i in range(len(predicted)):\n",
    "                    s += f'{i},{str(int(predicted[i]))}\\n'\n",
    "        s = s[:-1]\n",
    "        out_file.write(s)\n",
    "        \n",
    "save_predictions(model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 40.52982,
   "end_time": "2022-12-06T16:38:34.810075",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-12-06T16:37:54.280255",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
